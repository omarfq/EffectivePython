{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Item 39: Use `@classmethod` Polymorphism to Construct Objects Generically"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python supports polymorphism for both classes and objects. \n",
    "\n",
    "Polymorphism enbales multiple classes in a hierarchy to implement their own unique versions of a method. This means that many classes can fulfill the same interface or abstract base class while providing different functionality."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Say we want to write a MapReduce implementation and want a common class to represent the input data. We can\n",
    "# define such a class with a read method that musth be defined by subclasses\n",
    "class InputData:\n",
    "    def read(self):\n",
    "        raise NotImplementedError"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# We also have a concrete subclass of InputData that reads data from a disk\n",
    "class PathInputData(InputData):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "\n",
    "    def read(self):\n",
    "        with open(self.path) as f:\n",
    "            return f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# We'd want a similar abstract interface as that of read() for MapReduce worker that consumes he input data in\n",
    "# in a standard way\n",
    "class Worker:\n",
    "    def __init__(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        self.result = None\n",
    "\n",
    "    def map(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reduce(self, other):\n",
    "        raise NotImplementedError\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Here, we define a concrete subclass of Worker to implement the specific MapReduce function we want to apply\n",
    "class LineCountWorker(Worker):\n",
    "    def map(self):\n",
    "        data = self.input_data.read()\n",
    "        self.result = data.count('\\n')\n",
    "    \n",
    "    def reduce(self, other):\n",
    "        self.result += other.result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It ma look like the implementation is going great, but we've reached the biggest hurdle in all of this. What connects all of these pieces? We have a nice set of classes with reasonable interfaces and abstractions, but that's only useful once the sibjects are constructed. What's responsible for building the objects and orchestrating MapReduce?\n",
    "\n",
    "Simple approach: build and connect the objects with some helper functions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Here, we list the contents of a directory and construct a PathInputData instance for each file it contains\n",
    "import os\n",
    "\n",
    "def generate_inputs(data_dir):\n",
    "    for name in os.listdir(data_dir):\n",
    "        yield PathInputData(os.path.join(data_dir, name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Next, we create the LineCounterWorker instances by using the InputData instances returned by generate_inputs\n",
    "def create_workers(input_list):\n",
    "    workers = []\n",
    "    for input_data in input_list:\n",
    "        workers.append(LineCountWorker(input_data))\n",
    "    return workers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# We execute this Worker instances by fanning out the map step to multiple threads. Then, we call reduce\n",
    "# repeatedly to combine the results into one final value\n",
    "from threading import Thread\n",
    "\n",
    "def execute(workers):\n",
    "    threads = [Thread(target=w.map) for w in workers]\n",
    "    for thread in threads: thread.start()\n",
    "    for thread in threads: thread.join()\n",
    "\n",
    "    first, *rest = workers\n",
    "    for worker in rest:\n",
    "        first.reduce(worker)\n",
    "    return first.result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Finally, we connect all the pieces together in a function to run each step\n",
    "def mapreduce(data_dir):\n",
    "    inputs = generate_inputs(data_dir)\n",
    "    workers = create_workers(inputs)\n",
    "    return execute(workers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Make sure to run the following block of code to generate test input files*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Test this on some test input files\n",
    "import os\n",
    "import random\n",
    "\n",
    "def write_test_files(tmpdir):\n",
    "    os.makedirs(tmpdir)\n",
    "    for i in range(100):\n",
    "        with open(os.path.join(tmpdir, str(i)), 'w') as f:\n",
    "            f.write('\\n' * random.randint(0, 100))\n",
    "\n",
    "tmpdir = 'test_inputs'\n",
    "write_test_files(tmpdir)\n",
    "\n",
    "result = mapreduce(tmpdir)\n",
    "print(f'There are {result} lines')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 5210 lines\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The problem with the code above is that the `mapreduce` function is not generic at all. If we wanted to create another `InputData` or `Worker` subclass, we'd also have to rewrite the `generate_inputs`, `create_workers`, and `mapreduce` functions to match the new implementation.\n",
    "\n",
    "This problem boils down to needing a generic way to construct objects. Since Python only allows for the single constructor method (`__init__`), its unreasonable for us to require every `InputData` subclass to have a compatible constructor (as we would do in other programming languages).\n",
    "\n",
    "The best way to solve this issue is with *class method* polymorphism."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Here we apply the mentioned idea to the MapReduce classes. We extend the Inputdata class with a generic \n",
    "# @classmehtod that's responsible for creating a new InputData instance using a common interface\n",
    "class GenericInputData:\n",
    "    def read(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def generate_inputs(cls, config):\n",
    "        raise NotImplementedError"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Here, we use the config dictionary to find the directory to list for input files\n",
    "class PathInputData(GenericInputData):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "\n",
    "    def read(self):\n",
    "        with open(self.path) as f:\n",
    "            return f.read()\n",
    "\n",
    "    @classmethod\n",
    "    def generate_inputs(cls, config):\n",
    "        data_dir = config['data_dir']\n",
    "        for name in os.listdir(data_dir):\n",
    "            yield cls(os.path.join(data_dir, name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Similarly, we can makethe create_workers helper part of the GenericWorker class\n",
    "class GenericWorker:\n",
    "    def __init__(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        self.result = None\n",
    "\n",
    "    def map(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reduce(self, other):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def create_workers(cls, input_class, config):\n",
    "        workers = []\n",
    "        for input_data in input_class.generate_inputs(config):\n",
    "            workers.append(cls(input_data))\n",
    "        return workers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The call to `input_class.generate_inputs` is the polymorphism that the author is trying to show. We can see how `create_workers` calling `cls()` provides an alternative way to construct `GenericCoworker` objects besides using the `__init__` method directly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# The effect on our concrete GenericWorker subclass is nothing more than changing its parent\n",
    "class LineCountWorker(GenericWorker):\n",
    "    def map(self):\n",
    "        data = self.input_data.read()\n",
    "        self.result = data.count('\\n')\n",
    "    \n",
    "    def reduce(self, other):\n",
    "        self.result += other.result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Finally, we can rewrite the mapreduce function to be completely generic by calling create_workers\n",
    "def mapreduce(worker_class, input_class, config):\n",
    "    workers = worker_class.create_workers(input_class, config)\n",
    "    return execute(workers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Running the new worker on a set of test files produces the same result as the old implementation\n",
    "config = {'data_dir': tmpdir}\n",
    "result = mapreduce(LineCountWorker, PathInputData, config)\n",
    "print(f'There are {result} lines')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 5210 lines\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}